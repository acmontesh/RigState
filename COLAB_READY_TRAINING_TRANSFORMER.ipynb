{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TQutPRM1G8ql"
   },
   "source": [
    "# Training Time Series Classifiers Based on Deep Learning\n",
    "<strong>Abraham C. Montes</strong> <br>\n",
    "<a href=\"https://www.linkedin.com/in/abraham-c-montes-6661a841/\">LinkedIn</a>|<a href=\"https://www.abraham-montes.com/\">Personal Site</a><br>\n",
    "The University of Texas at Austin | <a href=\"https://drilling.utexas.edu/\">RAPID research consortium</a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PPOnIFzdG_LB"
   },
   "source": [
    "<strong> Description: </strong> <br>\n",
    "The objective of this notebook is to train time-series classifiers based on deep learning for rig/well activity identification. The models implemented here are of two types: An LSTM recurrent neural network and a transformer for time series classification. Both models are constructed using the PyTorch library and leverage GPU hardware for faster, more efficient training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ak1Do99HOZKR"
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "class LoggerDev:\n",
    "\n",
    "    def __init__( self,verbosity=2 ):\n",
    "      for handler in logging.root.handlers[:]:\n",
    "        logging.root.removeHandler(handler)\n",
    "      logging.basicConfig(   format='[%(levelname)s]......... %(message)s', level=logging.DEBUG   )\n",
    "      self.verbosity      =   verbosity\n",
    "\n",
    "    def setVerbosity( self,verbosity ):\n",
    "        self.verbosity      = verbosity\n",
    "        logging.info( f\"Verbosity has been set to {verbosity}\" )\n",
    "\n",
    "    def dbgMsg( self,msg=None ):\n",
    "        if (msg is not None) and (self.verbosity>1):\n",
    "            logging.debug(  msg  )\n",
    "\n",
    "    def infoMsg( self,msg=None ):\n",
    "        if (msg is not None) and (self.verbosity>1):\n",
    "            logging.info(  msg  )\n",
    "\n",
    "    def warningMsg( self,msg=None ):\n",
    "        if (msg is not None) and (self.verbosity>0):\n",
    "            logging.warning(  msg  )\n",
    "\n",
    "    def errorMsg( self,msg=None ):\n",
    "        if (msg is not None) and (self.verbosity>-1):\n",
    "            logging.error(  msg  )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vgtswEHYOLjg"
   },
   "outputs": [],
   "source": [
    "class Nomenclature:\n",
    "\n",
    "    DATE_MNEMONIC           = \"Date\"\n",
    "    BIT_DEPTH_MNEMO         = \"Bit Depth [ft]\"\n",
    "    DEPTH_MNEMONIC          = \"Measured Depth [ft]\"\n",
    "    DEPTH_MNEMONIC_METRIC   = \"Measured Depth [m]\"\n",
    "    TORTUOSITY_MNEMO        = \"Tortuosity Idx\"\n",
    "    INCLINATION_MNEMO       = 'Inclination [°]'\n",
    "    AZIMUTH_MNEMO           = 'Azimuth [°]'\n",
    "    DLS_MNEMO               = 'DLS [°/100 ft]'\n",
    "    GAMMA_RAY_LOG_MNEMO     = \"Gamma Ray [API]\"\n",
    "    ROP_MNEMO               = \"ROP [fph]\"\n",
    "    TORQUE_MNEMO            = \"Torque [lb-ft]\"\n",
    "    WOB_MNEMO               = \"Weight on Bit [klb]\"\n",
    "    STANDPIPE_PRESSURE_MNEMO=\"Standpipe Pressure [psi]\"\n",
    "    RPM_MNEMO               = \"Surface Rotation [rpm]\"\n",
    "    HOOK_LOAD_MNEMO         = \"Hook Load [klb]\"\n",
    "    HOLE_DEPTH_MNEMO        = \"Hole Depth [ft]\"\n",
    "    FLOW_IN_MNEMO           = \"Flow In [gpm]\"\n",
    "    BLOCK_POSITION_MNEMO    = \"Block Position [ft]\"\n",
    "    RIG_STATE_MNEMO         = \"Rig State\"\n",
    "    RIG_ACTIVITY_MNEMO      = \"Activity\"\n",
    "    SECTION_PHASE_MNEMO     = \"Section Operation Phase\"\n",
    "    TORTUOSITY_BIT_MNEMO    = 'Tortuosity Idx at Bit'\n",
    "    FLEX_RIGIDITY_BIT_MNEMO = 'Flex Rigidity Difference at Bit'\n",
    "    BLOCK_WEIGHT_MNEMO      = 'Block Weight [klb]'\n",
    "    TRIP_OUT_MNEMO          = \"Trip Out\"\n",
    "    DRILLING_MNEMO          = \"Drilling\"\n",
    "    CIRCULATION_MNEMO       = \"Circulation\"\n",
    "    BLOCK_WEIGHT_DELTA_MNEMO= \"delta\"\n",
    "    BLOCK_WEIGHT_DELTA_DATES_MNEMO=\"dates\"\n",
    "    BLOCK_POSITION_TREND_MNEMO='Block Position Trend'\n",
    "    FLOW_RATE_VARIABILITY_MNEMO='Flow Rate Variability'\n",
    "    FLOW_RATE_MEAN_MNEMO        ='Flow Rate Mean'\n",
    "    RPM_MEAN_MNEMO          = 'RPM Mean'\n",
    "    HOOK_LOAD_MEAN_MNEMO    = 'Hook Load Mean'\n",
    "    HOOK_LOAD_VARIABILITY_MNEMO='Hook Load Variability'\n",
    "    EFF_HOOK_LOAD_MNEMO     = 'Effective Hook Load [klb]'\n",
    "    ROP_MEAN_MNEMO          = 'ROP Mean'\n",
    "    BACKREAMING_MNEMO       = 117\n",
    "    TRIP_OUT_ELEV_MNEMO     = 112\n",
    "    PUMPING_OUT_MNEMO       = 115\n",
    "    REAMING_MNEMO           = 116\n",
    "    DRILLING_ROT_MNEMO      = 119\n",
    "    CONNECTION_MNEMO        = 118\n",
    "    TRANSFORMER_MODEL_MNEMO = \"transformer\"\n",
    "    LSTM_MODEL_MNEMO        = \"lstm\"\n",
    "    GOAL_RIG_STATES         = [111,112,114,115,116,117,118,119,120,121]\n",
    "    DICT_RIG_STATES         = {\n",
    "                                    111:\"Tripping in on elevators\",\n",
    "                                    112:\"Tripping out on elevators\",\n",
    "                                    114:\"Washing down\",\n",
    "                                    115:\"Pumping out\",\n",
    "                                    116:\"Reaming\",\n",
    "                                    117:\"Backreaming\",\n",
    "                                    118:\"Connection/Other surface operations\",\n",
    "                                    119:\"Drilling (with surface rotation)\",\n",
    "                                    120:\"Drilling (sliding)\",\n",
    "                                    121:\"Circulating\"\n",
    "                                }\n",
    "    CONVERTION_HASH_TABLE   = {\n",
    "            \"TIME\":                             DATE_MNEMONIC,\n",
    "            \"DBTM\":                             BIT_DEPTH_MNEMO,\n",
    "            \"BPOS\":                             BLOCK_POSITION_MNEMO,\n",
    "            \"MFIA\":                             FLOW_IN_MNEMO,\n",
    "            \"DMEA\":                             HOLE_DEPTH_MNEMO,\n",
    "            \"HKLA\":                             HOOK_LOAD_MNEMO,\n",
    "            \"RPMA\":                             RPM_MNEMO,\n",
    "            \"SPPA\":                             STANDPIPE_PRESSURE_MNEMO,\n",
    "            \"WOBA\":                             WOB_MNEMO,\n",
    "            \"TQA\":                              TORQUE_MNEMO,\n",
    "            # \"ROPA__\":                           ROP_MNEMO,\n",
    "            #Note (10/21/24): For some unknown issue within Shell's system, the 'ROPA__' channel\n",
    "            # is sometimes unavailable (full with NaNs). An alternative is the one below.\n",
    "            \"ROPA__SHELL_CALCULATION_INPUT_TIME\":ROP_MNEMO,\n",
    "            \"MD\":                               DEPTH_MNEMONIC,\n",
    "            \"INCLINATION\":                      INCLINATION_MNEMO,\n",
    "            \"AZIMUTH\":                          AZIMUTH_MNEMO,\n",
    "            \"DLS\":                              DLS_MNEMO,\n",
    "            \"DEPTH\":                            DEPTH_MNEMONIC,\n",
    "            \"SGRC\":                             GAMMA_RAY_LOG_MNEMO\n",
    "        }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "owhipDAbOS4m"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "\n",
    "class TimeSeriesTransformer( nn.Module ):\n",
    "\n",
    "    def __init__( self, nInputs,dModel,nHead,nLayers,dimFeedForward,nOutput,dropoutRate=0.1 ):\n",
    "        super( TimeSeriesTransformer,self ).__init__( )\n",
    "        self.D                  = nInputs\n",
    "        self.dModel             = dModel\n",
    "        self.inputProjection    = nn.Linear(  nInputs, dModel  )\n",
    "        self.posEncoding        = nn.Parameter( self._generatePosEncoding( dModel, maxLength=500 ), requires_grad=False )\n",
    "        encoderLayer            = nn.TransformerEncoderLayer( d_model=dModel, nhead=nHead, dim_feedforward=dimFeedForward, dropout=dropoutRate )\n",
    "        self.transformerEncoder = nn.TransformerEncoder(encoderLayer, num_layers=nLayers)\n",
    "        self.fc                 = nn.Linear( dModel, nOutput  )\n",
    "        self.softmax            = nn.Softmax( dim=1 )\n",
    "\n",
    "    def _generatePosEncoding(  self, dModel, maxLength  ):\n",
    "        position                = torch.arange(  0, maxLength  ).unsqueeze(1)\n",
    "        divTerm                 = torch.exp(torch.arange(  0, dModel, 2) * -(np.log(10000.0) / dModel)  )\n",
    "        posEncoding             = torch.zeros(  maxLength, dModel  )\n",
    "        posEncoding[ :, 0::2 ]    = torch.sin(  position * divTerm  )\n",
    "        posEncoding[ :, 1::2 ]    = torch.cos(  position * divTerm  )\n",
    "        return posEncoding.unsqueeze( 0 )\n",
    "\n",
    "    def forward( self, x ):\n",
    "        x                       = self.inputProjection( x )\n",
    "        x                       = x + self.posEncoding[ :, :x.size(1), : ]\n",
    "        x                       = x.permute(1, 0, 2)\n",
    "        x                       = self.transformerEncoder( x )\n",
    "        x                       = x[ -1, :, : ]\n",
    "        output                  = self.fc( x )\n",
    "        return self.softmax( output )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9RV9k_v6HM3L"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import (MultipleLocator, AutoMinorLocator)\n",
    "import scipy as sp\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import os\n",
    "import sys\n",
    "import seaborn as sb\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "class Trainer:\n",
    "\n",
    "    FDICT_PLOTS                 = {'family':'Arial','size':8}\n",
    "\n",
    "    def __init__( self ):\n",
    "        self.logger             = LoggerDev(  )\n",
    "        self.dataSets           = [  ]\n",
    "        self.blockWeights       = [  ]\n",
    "        self.nom                = Nomenclature(  )\n",
    "        self.labelPreds         = {  }\n",
    "\n",
    "    def loadData( self,pathFolder,blockWeights={  } ):\n",
    "        for file in os.listdir( pathFolder ):\n",
    "            if file==\".ipynb_checkpoints\":  continue\n",
    "            df                  = pd.read_csv( pathFolder+\"/\"+file,parse_dates=[ self.nom.DATE_MNEMONIC ] )\n",
    "            if file[ :-4 ] in list( blockWeights.keys(  ) ):\n",
    "                bW              =   blockWeights[ file[ :-4 ] ]\n",
    "            else:\n",
    "                bW              =   self._getBlockWeight( df )\n",
    "                self.logger.warningMsg( f\"The block weight for the {file[ :-4 ]} well was not provided. Therefore, it has been inferred. Its value is: {bW}\" )\n",
    "            self.dataSets.append( df )\n",
    "            self.blockWeights.append( bW )\n",
    "            self.logger.infoMsg( f\"The current block weight is: {bW} klb.\" )\n",
    "        self.logger.infoMsg( f\"Data has been loaded correctly to the trainer. In total, {len( self.dataSets )} dataframes have been loaded.\" )\n",
    "\n",
    "    def _loadCheckPoint( self, currentCheckPointPath, model, optimizer ):\n",
    "        checkpoint          = torch.load(  currentCheckPointPath, weights_only=False  )\n",
    "        model.load_state_dict(  checkpoint['model_state_dict']  )\n",
    "        optimizer.load_state_dict(  checkpoint['optimizer_state_dict']  )\n",
    "        return model, optimizer\n",
    "\n",
    "    def trainModel(  self, modelType, batchSize=32, nEpochs=200, learningRate=0.0001, currentCheckPointPath=None,\n",
    "                    saveModel=True, savePath=\"model_.pth\", **kwargs  ):\n",
    "        if len( self.dataSets )==0:\n",
    "            self.logger.errorMsg( \"No data has been loaded to the trainer. Use the loadData( ) function before training a model.\" )\n",
    "            sys.exit( 1 );\n",
    "        model, optimizer        = self._createModel( modelType,learningRate, **kwargs )\n",
    "        self.logger.infoMsg( f\"The {modelType} model has been created.\" )\n",
    "        currEpoch               = 0\n",
    "        trainLosses             = np.zeros( nEpochs*len( self.dataSets ) )\n",
    "        if currentCheckPointPath is not None:\n",
    "            model, optimizer    = self._loadCheckPoint( currentCheckPointPath, model, optimizer )\n",
    "            self.logger.infoMsg( \"Checkpoint loaded successfully. Resuming training...\" )\n",
    "        else:                   self.logger.infoMsg( \"Starting training...\" )\n",
    "        for k,ds in enumerate( self.dataSets ):\n",
    "            X_train, y_train, _     = self.extractFeatures( ds,self.blockWeights[ k ],modelType=modelType )\n",
    "            criterion               = nn.CrossEntropyLoss(  )\n",
    "            dataset                 = TensorDataset( X_train, y_train )\n",
    "            dataLoader              = DataLoader( dataset, batch_size=batchSize, shuffle=True )\n",
    "            self.logger.infoMsg( \"Data loaded to the torch DataLoader object.\" )\n",
    "            for epoch in range( nEpochs ):\n",
    "                if epoch==0: self.logger.infoMsg( f\"Initiating forward pass (epoch {epoch}) for dataset {k}.\" )\n",
    "                model.train(  )\n",
    "                runningLoss         = 0.0\n",
    "                correctPreds        = 0\n",
    "                totalPreds          = 0\n",
    "                for inputs, labels in dataLoader:\n",
    "                    optimizer.zero_grad(  )\n",
    "                    outputs         = model( inputs )\n",
    "                    loss            = criterion( outputs, labels )\n",
    "                    loss.backward(  )\n",
    "                    optimizer.step(  )\n",
    "                    runningLoss     += loss.item(  )\n",
    "                    _, predicted    = torch.max( outputs, 1 )\n",
    "                    correctPreds    += ( predicted == labels ).sum(  ).item(  )\n",
    "                    totalPreds      += labels.size( 0 )\n",
    "                epochLoss               = runningLoss / len(  dataLoader  )\n",
    "                trainLosses[ k*nEpochs+epoch ] = epochLoss\n",
    "                self.logger.infoMsg( f'[TRAINING MSG>>>]..... Epoch {epoch+1}/{nEpochs}, Train Loss: {loss.item(  ):.4f}')\n",
    "            self._saveCheckpoint( model,optimizer,epoch,trainLosses[-1],modelType,codeName=f\"_{k}\" )\n",
    "            self.logger.infoMsg( f\"Successfully saved checkpoint: {modelType}_{k}_chk\" )\n",
    "        if saveModel:\n",
    "            torch.save(  model.state_dict(  ), savePath  )\n",
    "            self.logger.infoMsg( f\"Successfully saved {modelType} model: {savePath}\" )\n",
    "        return trainLosses, model\n",
    "\n",
    "    def _getBlockWeight( self,dataSet ):\n",
    "        return dataSet[ dataSet[ self.nom.HOOK_LOAD_MNEMO ]>0.0][ self.nom.HOOK_LOAD_MNEMO ].mode(  )[ 0 ]\n",
    "\n",
    "    def extractFeatures( self, df, blockWeight, modelType,slidingWindow = 5 ):\n",
    "        device          = torch.device( \"cuda:0\" if torch.cuda.is_available( ) else \"cpu\" )\n",
    "        typeDevice      = \"GPU\" if torch.cuda.is_available( ) else \"CPU\"\n",
    "        self.logger.infoMsg(f\"Working on: {typeDevice}, model {torch.cuda.get_device_name(0)}\")\n",
    "        df[self.nom.EFF_HOOK_LOAD_MNEMO]            = np.where(df[self.nom.HOOK_LOAD_MNEMO]>0,df[self.nom.HOOK_LOAD_MNEMO]-blockWeight,df[self.nom.HOOK_LOAD_MNEMO])\n",
    "        df[self.nom.BLOCK_POSITION_TREND_MNEMO]     = df[self.nom.BLOCK_POSITION_MNEMO].rolling(window=slidingWindow).apply(self._trend,raw=True,engine='cython')\n",
    "        df[self.nom.FLOW_RATE_VARIABILITY_MNEMO]    = df[self.nom.FLOW_IN_MNEMO].rolling(window=slidingWindow).std(  )\n",
    "        df[self.nom.FLOW_RATE_MEAN_MNEMO]           = df[self.nom.FLOW_IN_MNEMO].rolling(window=slidingWindow).mean(  )\n",
    "        df[self.nom.RPM_MEAN_MNEMO]                 = df[self.nom.RPM_MNEMO].rolling(window=slidingWindow).mean(  )\n",
    "        df[self.nom.HOOK_LOAD_MEAN_MNEMO]           = df[self.nom.EFF_HOOK_LOAD_MNEMO].rolling(window=slidingWindow).mean(  )\n",
    "        df[self.nom.HOOK_LOAD_VARIABILITY_MNEMO]    = df[self.nom.EFF_HOOK_LOAD_MNEMO].rolling(window=slidingWindow).std(  )\n",
    "        df[self.nom.ROP_MEAN_MNEMO]                 = df[self.nom.ROP_MNEMO].rolling(window=slidingWindow).mean(  )\n",
    "        dfTraining                                  = df[[self.nom.BLOCK_POSITION_TREND_MNEMO,\n",
    "                                                            self.nom.FLOW_RATE_VARIABILITY_MNEMO,\n",
    "                                                            self.nom.FLOW_RATE_MEAN_MNEMO,\n",
    "                                                            self.nom.RPM_MEAN_MNEMO,\n",
    "                                                            self.nom.HOOK_LOAD_MEAN_MNEMO,\n",
    "                                                            self.nom.ROP_MEAN_MNEMO,\n",
    "                                                            self.nom.HOOK_LOAD_VARIABILITY_MNEMO,\n",
    "                                                            self.nom.RIG_STATE_MNEMO]]\n",
    "        dfTraining                                  = dfTraining.dropna( axis=0 )\n",
    "        X                       = dfTraining.iloc[:,:-1].values\n",
    "        y                       = df[self.nom.RIG_STATE_MNEMO].values\n",
    "        y                       = pd.get_dummies( y )\n",
    "        y                       = y.reindex( columns=self.nom.GOAL_RIG_STATES,fill_value=False )\n",
    "        y                       = y.values\n",
    "        scaler                  = StandardScaler( )\n",
    "        XSc                     = scaler.fit_transform( X )\n",
    "        XF                      = [ ]\n",
    "        yF                      = [ ]\n",
    "        for t in range( XSc.shape[ 0 ]-slidingWindow ):\n",
    "            x                   = XSc[ t:t+slidingWindow,: ]\n",
    "            XF.append( x )\n",
    "            ny                  = y[ t+slidingWindow-1,: ]\n",
    "            yF.append( ny )\n",
    "        XF                      = np.array( XF ).reshape( -1,slidingWindow,XSc.shape[1] )\n",
    "        yF                      = np.array( yF ).reshape( -1,y.shape[1] )\n",
    "        X_train                 = torch.from_numpy(XF.astype(np.float32)).to( device )\n",
    "        y_train                 = torch.from_numpy(yF.astype(np.float32))\n",
    "        y_train                 = torch.argmax( y_train, dim=1 ).to( device )\n",
    "        # if modelType==\"lstm\":\n",
    "        #     y_train                 = torch.from_numpy(yF.astype(np.float32)).to( device )\n",
    "        # else:\n",
    "        #     y_train                 = torch.from_numpy(yF.astype(np.float32))\n",
    "        #     y_train                 = torch.argmax( y_train, dim=1 ).to( device )\n",
    "        return X_train,y_train,device\n",
    "\n",
    "    def plotLosses( self, trainingLoss, testLoss, outPath=\"loss_curve.png\" ):\n",
    "        fig,ax                    = plt.subplots( figsize=(6.83,3.33) )\n",
    "        ax.plot( np.arange( len(trainingLoss) ), trainingLoss, lw=1.5, color='teal',label=\"Training Loss\" )\n",
    "        if not testLoss is None: ax.plot( np.arange( len(testLoss) ), testLoss, lw=1.5, color='red',ls='--',label=\"Test Loss\" )\n",
    "        ax.set_xlabel( 'Epoch', fontdict={ **self.FDICT_PLOTS,'weight':'bold'} )\n",
    "        ax.set_ylabel( 'Loss (Cross Entropy)', fontdict={ **self.FDICT_PLOTS,'weight':'bold'} )\n",
    "        ax.set_xticklabels( ax.get_xticklabels( ), fontdict=self.FDICT_PLOTS )\n",
    "        ax.set_yticklabels( ax.get_yticklabels( ), fontdict=self.FDICT_PLOTS )\n",
    "        ax.yaxis.set_minor_locator( AutoMinorLocator( ) )\n",
    "        ax.xaxis.set_minor_locator( AutoMinorLocator( ) )\n",
    "        ax.legend(  )\n",
    "        plt.tight_layout(  )\n",
    "        fig.savefig( outPath,dpi=600 )\n",
    "\n",
    "    def _plotFancyContingencyTable(  self, confMatrix, classNames,outPath=\"contingency_table.png\"  ):\n",
    "        fig, ax                 = plt.subplots(  figsize=(  6.83, 4  ))\n",
    "        buff                    = sb.heatmap(  confMatrix, annot=True, fmt=\"d\", cmap=\"Blues\",\n",
    "                        xticklabels=classNames, yticklabels=classNames, ax=ax, annot_kws={ **self.FDICT_PLOTS }  )\n",
    "        ax.set_xlabel(  \"Predicted Labels\",fontdict={ **self.FDICT_PLOTS, 'weight':'bold' }  )\n",
    "        ax.set_ylabel(  \"True Labels\",fontdict={ **self.FDICT_PLOTS, 'weight':'bold' }  )\n",
    "        ax.set_title(  \"Confusion Matrix\",fontdict={ **self.FDICT_PLOTS, 'weight':'bold' }  )\n",
    "        ax.set_xticklabels( ax.get_xticklabels( ), fontdict=self.FDICT_PLOTS )\n",
    "        ax.set_yticklabels( ax.get_yticklabels( ), fontdict=self.FDICT_PLOTS )\n",
    "        plt.tight_layout(  )\n",
    "        fig.savefig( outPath,dpi=600 )\n",
    "\n",
    "    def _saveCheckpoint( self,model, optimizer, epoch, loss, modelType, path='checkpoint.pth',codeName=\"_\" ):\n",
    "        newPath    = f\"{modelType}{codeName}_chk\"\n",
    "        checkpoint = {\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(  ),\n",
    "            'optimizer_state_dict': optimizer.state_dict(  ),\n",
    "            'loss': loss\n",
    "        }\n",
    "        torch.save(  checkpoint, newPath  )\n",
    "        self.logger.infoMsg( f\"Checkpoint saved at epoch {epoch}.\" )\n",
    "\n",
    "    def _createModel( self,modelType,learningRate=0.0001,**kwargs ):\n",
    "        device = torch.device( \"cuda:0\" if torch.cuda.is_available( ) else \"cpu\" )\n",
    "        if modelType==self.nom.TRANSFORMER_MODEL_MNEMO:\n",
    "            model                   = self.createModelTransformer( device, **kwargs )\n",
    "        elif modelType==self.nom.LSTM_MODEL_MNEMO:\n",
    "            model                   = self.createModelLSTM( device, **kwargs )\n",
    "        optimizer                   = torch.optim.Adam( model.parameters( ),lr=learningRate )\n",
    "        return model,optimizer\n",
    "\n",
    "    def createModelTransformer( self, device, **kwargs ):\n",
    "        nInputs         = 7 if \"nInputs\" not in kwargs else kwargs[\"nInputs\"]\n",
    "        nLayers         = 3 if \"nLayers\" not in kwargs else kwargs[\"nLayers\"]\n",
    "        dModel          = 256 if \"dModel\" not in kwargs else kwargs[\"dModel\"]\n",
    "        nOutput         = 10 if \"nOutput\" not in kwargs else kwargs[\"nOutput\"]\n",
    "        nHead           = 8 if \"nHead\" not in kwargs else kwargs[\"nHead\"]\n",
    "        dimFeedForward  = 512 if \"dimFeedForward\" not in kwargs else kwargs[\"dimFeedForward\"]\n",
    "        model           = TimeSeriesTransformer(  nInputs=nInputs,nLayers=nLayers,dModel=dModel,\n",
    "                                        nOutput=nOutput,nHead=nHead,dimFeedForward=dimFeedForward )\n",
    "        model.to( device )\n",
    "        return model\n",
    "\n",
    "    def createModelLSTM( self,device, **kwargs ):\n",
    "        nInputs         = 7 if \"nInputs\" not in kwargs else kwargs[\"nInputs\"]\n",
    "        nLayers         = 3 if \"nLayers\" not in kwargs else kwargs[\"nLayers\"]\n",
    "        nHidden         = 30 if \"nHidden\" not in kwargs else kwargs[\"nHidden\"]\n",
    "        nOutput         = 10 if \"nOutput\" not in kwargs else kwargs[\"nOutput\"]\n",
    "        model           = LSTMClassifier(  nInputs=nInputs,nLayers=nLayers, nOutput=nOutput,nHidden=nHidden )\n",
    "        model.to( device )\n",
    "        return model\n",
    "\n",
    "    def _trend( self,window ):\n",
    "        slope,_,_,_,_         = sp.stats.linregress( np.arange(len( window )), window )\n",
    "        return slope\n",
    "\n",
    "    def testModel( self,pathTest,blockWeights={  },batchSize=32,loadFromPath=None,modelType=None,model=None,**kwargs ):\n",
    "        if (loadFromPath is None) & (model is None):\n",
    "            self.logger.errorMsg( \"Cannot test a model if no model is indicated. Either specify the torch model object or a path to a .pth file containing a model.\" )\n",
    "            sys.exit( 1 )\n",
    "        if loadFromPath is not None:\n",
    "            if modelType is None:\n",
    "                self.logger.errorMsg( \"The type of model must be specified. Options: 'lstm', 'transformer'.\" )\n",
    "                sys.exit( 1 )\n",
    "            thisModel           = self._createModel( modelType=modelType,**kwargs )\n",
    "        else:\n",
    "            thisModel           = model\n",
    "        thisModel.eval(  )\n",
    "        nSamples                = 0\n",
    "        nCorrectSamples         = 0\n",
    "        self.dataSets           = [ ]\n",
    "        self.blockWeights       = [ ]\n",
    "        allYPred                = [  ]\n",
    "        allYTrue                = [  ]\n",
    "        self.loadData( pathTest,blockWeights )\n",
    "        for k,testDS in enumerate(  self.dataSets  ):\n",
    "            X_test,y_test,device    = self.extractFeatures( testDS,blockWeight=blockWeights[ k ] )\n",
    "            for i in range( X_test.shape[0]//batchSize ):\n",
    "                small_X_test        = X_test[  i*batchSize:i*batchSize+batchSize  ]\n",
    "                small_X_test        = small_X_test.to( device )\n",
    "                with torch.no_grad(  ):\n",
    "                    yPred               = thisModel( small_X_test )\n",
    "                    small_y_test        = y_test[  i*batchSize:i*batchSize+batchSize  ]\n",
    "                    small_y_test        = small_y_test.to( device )\n",
    "                    _, yPredLabels      = torch.max( yPred, dim=1 )\n",
    "                    yPred_np            = yPredLabels.cpu(  ).numpy(  )\n",
    "                    yTrue_np            = small_y_test.cpu(  ).numpy(  )\n",
    "                    if len( yTrue_np.shape ) > 1 and yTrue_np.shape[1] > 1:\n",
    "                        yTrue_np        = np.argmax( yTrue_np, axis=1 )\n",
    "                    allYPred.extend( yPred_np )\n",
    "                    allYTrue.extend( yTrue_np )\n",
    "                    nCorrectSamples     += (yPred_np == yTrue_np).sum(  )\n",
    "                    nSamples            += batchSize\n",
    "        accuracy = nCorrectSamples / nSamples\n",
    "        self.logger.infoMsg(f'Accuracy: {accuracy:.4f}')\n",
    "        conf_matrix = confusion_matrix(  allYTrue, allYPred, labels=np.arange( 9 )  )\n",
    "        classNames = [  self.nom.DICT_RIG_STATES[ i ] for i in self.nom.GOAL_RIG_STATES  ]\n",
    "        self._plotFancyContingencyTable( conf_matrix, classNames )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bCA-lw81OjAY",
    "outputId": "8e259dc6-ad1e-4bf6-97b7-fd6b1615e711"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO]......... Data has been loaded correctly to the trainer. In total, 1 dataframes have been loaded.\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(  )\n",
    "trainer.loadData( \"data\",blockWeights={\"ANNOTATED_mb2314\":158} )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "PDJsxXbPOq4N",
    "outputId": "8cb7185c-0e45-4f99-a6d3-8ed3c58f9c7b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "[INFO]......... The transformer model has been created.\n",
      "[INFO]......... Checkpoint loaded successfully. Resuming training...\n",
      "[INFO]......... Working on: GPU, model NVIDIA A100-SXM4-40GB\n",
      "[INFO]......... Data loaded to the torch DataLoader object.\n",
      "[INFO]......... Initiating forward pass (epoch 0) for dataset 0.\n",
      "[INFO]......... [TRAINING MSG>>>]..... Epoch 1/200, Train Loss: 1.5014\n",
      "[INFO]......... [TRAINING MSG>>>]..... Epoch 2/200, Train Loss: 1.4984\n",
      "[INFO]......... [TRAINING MSG>>>]..... Epoch 3/200, Train Loss: 1.4974\n",
      "[INFO]......... [TRAINING MSG>>>]..... Epoch 4/200, Train Loss: 1.4974\n",
      "[INFO]......... [TRAINING MSG>>>]..... Epoch 5/200, Train Loss: 1.4874\n",
      "[INFO]......... [TRAINING MSG>>>]..... Epoch 6/200, Train Loss: 1.4976\n",
      "[INFO]......... [TRAINING MSG>>>]..... Epoch 7/200, Train Loss: 1.4922\n",
      "[INFO]......... [TRAINING MSG>>>]..... Epoch 8/200, Train Loss: 1.4984\n",
      "[INFO]......... [TRAINING MSG>>>]..... Epoch 9/200, Train Loss: 1.4964\n",
      "[INFO]......... [TRAINING MSG>>>]..... Epoch 10/200, Train Loss: 1.4924\n",
      "[INFO]......... [TRAINING MSG>>>]..... Epoch 11/200, Train Loss: 1.4964\n",
      "[INFO]......... [TRAINING MSG>>>]..... Epoch 12/200, Train Loss: 1.4934\n",
      "[INFO]......... [TRAINING MSG>>>]..... Epoch 13/200, Train Loss: 1.4904\n",
      "[INFO]......... [TRAINING MSG>>>]..... Epoch 14/200, Train Loss: 1.4906\n",
      "[INFO]......... [TRAINING MSG>>>]..... Epoch 15/200, Train Loss: 1.4974\n",
      "[INFO]......... [TRAINING MSG>>>]..... Epoch 16/200, Train Loss: 1.4957\n",
      "[INFO]......... [TRAINING MSG>>>]..... Epoch 17/200, Train Loss: 1.5075\n",
      "[INFO]......... [TRAINING MSG>>>]..... Epoch 18/200, Train Loss: 1.4873\n",
      "[INFO]......... [TRAINING MSG>>>]..... Epoch 19/200, Train Loss: 1.5004\n",
      "[INFO]......... [TRAINING MSG>>>]..... Epoch 20/200, Train Loss: 1.4922\n",
      "[INFO]......... [TRAINING MSG>>>]..... Epoch 21/200, Train Loss: 1.4883\n",
      "[INFO]......... [TRAINING MSG>>>]..... Epoch 22/200, Train Loss: 1.4873\n",
      "[INFO]......... [TRAINING MSG>>>]..... Epoch 23/200, Train Loss: 1.4864\n",
      "[INFO]......... [TRAINING MSG>>>]..... Epoch 24/200, Train Loss: 1.4921\n",
      "[INFO]......... [TRAINING MSG>>>]..... Epoch 25/200, Train Loss: 1.4821\n",
      "[INFO]......... [TRAINING MSG>>>]..... Epoch 26/200, Train Loss: 1.4896\n",
      "[INFO]......... [TRAINING MSG>>>]..... Epoch 27/200, Train Loss: 1.4873\n",
      "[INFO]......... [TRAINING MSG>>>]..... Epoch 28/200, Train Loss: 1.4853\n",
      "[INFO]......... [TRAINING MSG>>>]..... Epoch 29/200, Train Loss: 1.4914\n",
      "[INFO]......... [TRAINING MSG>>>]..... Epoch 30/200, Train Loss: 1.5018\n",
      "[INFO]......... [TRAINING MSG>>>]..... Epoch 31/200, Train Loss: 1.4994\n",
      "[INFO]......... [TRAINING MSG>>>]..... Epoch 32/200, Train Loss: 1.4853\n",
      "[INFO]......... [TRAINING MSG>>>]..... Epoch 33/200, Train Loss: 1.4973\n",
      "[INFO]......... [TRAINING MSG>>>]..... Epoch 34/200, Train Loss: 1.4944\n",
      "[INFO]......... [TRAINING MSG>>>]..... Epoch 35/200, Train Loss: 1.4934\n",
      "[INFO]......... [TRAINING MSG>>>]..... Epoch 36/200, Train Loss: 1.4905\n",
      "[INFO]......... [TRAINING MSG>>>]..... Epoch 37/200, Train Loss: 1.4954\n",
      "[INFO]......... [TRAINING MSG>>>]..... Epoch 38/200, Train Loss: 1.4953\n",
      "[INFO]......... [TRAINING MSG>>>]..... Epoch 39/200, Train Loss: 1.5043\n",
      "[INFO]......... [TRAINING MSG>>>]..... Epoch 40/200, Train Loss: 1.5076\n",
      "[INFO]......... [TRAINING MSG>>>]..... Epoch 41/200, Train Loss: 1.5125\n",
      "[INFO]......... [TRAINING MSG>>>]..... Epoch 42/200, Train Loss: 1.4904\n",
      "[INFO]......... [TRAINING MSG>>>]..... Epoch 43/200, Train Loss: 1.4893\n",
      "[INFO]......... [TRAINING MSG>>>]..... Epoch 44/200, Train Loss: 1.4843\n",
      "[INFO]......... [TRAINING MSG>>>]..... Epoch 45/200, Train Loss: 1.4914\n",
      "[INFO]......... [TRAINING MSG>>>]..... Epoch 46/200, Train Loss: 1.4962\n",
      "[INFO]......... [TRAINING MSG>>>]..... Epoch 47/200, Train Loss: 1.4954\n",
      "[INFO]......... [TRAINING MSG>>>]..... Epoch 48/200, Train Loss: 1.4937\n",
      "[INFO]......... [TRAINING MSG>>>]..... Epoch 49/200, Train Loss: 1.4893\n",
      "[INFO]......... [TRAINING MSG>>>]..... Epoch 50/200, Train Loss: 1.4944\n",
      "[INFO]......... [TRAINING MSG>>>]..... Epoch 51/200, Train Loss: 1.5004\n",
      "[INFO]......... [TRAINING MSG>>>]..... Epoch 52/200, Train Loss: 1.4904\n",
      "[INFO]......... [TRAINING MSG>>>]..... Epoch 53/200, Train Loss: 1.4843\n",
      "[INFO]......... [TRAINING MSG>>>]..... Epoch 54/200, Train Loss: 1.4994\n",
      "[INFO]......... [TRAINING MSG>>>]..... Epoch 55/200, Train Loss: 1.4974\n",
      "[INFO]......... [TRAINING MSG>>>]..... Epoch 56/200, Train Loss: 1.4914\n",
      "[INFO]......... [TRAINING MSG>>>]..... Epoch 57/200, Train Loss: 1.5034\n",
      "[INFO]......... [TRAINING MSG>>>]..... Epoch 58/200, Train Loss: 1.4944\n",
      "[INFO]......... [TRAINING MSG>>>]..... Epoch 59/200, Train Loss: 1.4873\n",
      "[INFO]......... [TRAINING MSG>>>]..... Epoch 60/200, Train Loss: 1.4972\n",
      "[INFO]......... [TRAINING MSG>>>]..... Epoch 61/200, Train Loss: 1.4869\n",
      "[INFO]......... [TRAINING MSG>>>]..... Epoch 62/200, Train Loss: 1.4893\n",
      "[INFO]......... [TRAINING MSG>>>]..... Epoch 63/200, Train Loss: 1.4998\n",
      "[INFO]......... [TRAINING MSG>>>]..... Epoch 64/200, Train Loss: 1.4934\n",
      "[INFO]......... [TRAINING MSG>>>]..... Epoch 65/200, Train Loss: 1.4874\n",
      "[INFO]......... [TRAINING MSG>>>]..... Epoch 66/200, Train Loss: 1.4853\n",
      "[INFO]......... [TRAINING MSG>>>]..... Epoch 67/200, Train Loss: 1.4908\n",
      "[INFO]......... [TRAINING MSG>>>]..... Epoch 68/200, Train Loss: 1.4959\n",
      "[INFO]......... [TRAINING MSG>>>]..... Epoch 69/200, Train Loss: 1.4964\n",
      "[INFO]......... [TRAINING MSG>>>]..... Epoch 70/200, Train Loss: 1.5004\n",
      "[INFO]......... [TRAINING MSG>>>]..... Epoch 71/200, Train Loss: 1.5004\n",
      "[INFO]......... [TRAINING MSG>>>]..... Epoch 72/200, Train Loss: 1.5024\n",
      "[INFO]......... [TRAINING MSG>>>]..... Epoch 73/200, Train Loss: 1.4964\n",
      "[INFO]......... [TRAINING MSG>>>]..... Epoch 74/200, Train Loss: 1.4954\n",
      "[INFO]......... [TRAINING MSG>>>]..... Epoch 75/200, Train Loss: 1.4823\n",
      "[INFO]......... [TRAINING MSG>>>]..... Epoch 76/200, Train Loss: 1.4934\n",
      "[INFO]......... [TRAINING MSG>>>]..... Epoch 77/200, Train Loss: 1.4893\n",
      "[INFO]......... [TRAINING MSG>>>]..... Epoch 78/200, Train Loss: 1.4873\n",
      "[INFO]......... [TRAINING MSG>>>]..... Epoch 79/200, Train Loss: 1.4893\n",
      "[INFO]......... [TRAINING MSG>>>]..... Epoch 80/200, Train Loss: 1.4974\n",
      "[INFO]......... [TRAINING MSG>>>]..... Epoch 81/200, Train Loss: 1.4966\n",
      "[INFO]......... [TRAINING MSG>>>]..... Epoch 82/200, Train Loss: 1.4945\n",
      "[INFO]......... [TRAINING MSG>>>]..... Epoch 83/200, Train Loss: 1.4914\n",
      "[INFO]......... [TRAINING MSG>>>]..... Epoch 84/200, Train Loss: 1.4914\n",
      "[INFO]......... [TRAINING MSG>>>]..... Epoch 85/200, Train Loss: 1.4898\n",
      "[INFO]......... [TRAINING MSG>>>]..... Epoch 86/200, Train Loss: 1.4883\n",
      "[INFO]......... [TRAINING MSG>>>]..... Epoch 87/200, Train Loss: 1.4904\n",
      "[INFO]......... [TRAINING MSG>>>]..... Epoch 88/200, Train Loss: 1.4934\n",
      "[INFO]......... [TRAINING MSG>>>]..... Epoch 89/200, Train Loss: 1.4914\n",
      "[INFO]......... [TRAINING MSG>>>]..... Epoch 90/200, Train Loss: 1.4974\n",
      "[INFO]......... [TRAINING MSG>>>]..... Epoch 91/200, Train Loss: 1.5012\n",
      "[INFO]......... [TRAINING MSG>>>]..... Epoch 92/200, Train Loss: 1.4805\n",
      "[INFO]......... [TRAINING MSG>>>]..... Epoch 93/200, Train Loss: 1.4903\n",
      "[INFO]......... [TRAINING MSG>>>]..... Epoch 94/200, Train Loss: 1.4813\n",
      "[INFO]......... [TRAINING MSG>>>]..... Epoch 95/200, Train Loss: 1.4904\n",
      "[INFO]......... [TRAINING MSG>>>]..... Epoch 96/200, Train Loss: 1.4923\n",
      "[INFO]......... [TRAINING MSG>>>]..... Epoch 97/200, Train Loss: 1.4981\n",
      "[INFO]......... [TRAINING MSG>>>]..... Epoch 98/200, Train Loss: 1.4954\n",
      "[INFO]......... [TRAINING MSG>>>]..... Epoch 99/200, Train Loss: 1.4924\n",
      "[INFO]......... [TRAINING MSG>>>]..... Epoch 100/200, Train Loss: 1.4803\n",
      "[INFO]......... [TRAINING MSG>>>]..... Epoch 101/200, Train Loss: 1.4863\n",
      "[INFO]......... [TRAINING MSG>>>]..... Epoch 102/200, Train Loss: 1.4883\n",
      "[INFO]......... [TRAINING MSG>>>]..... Epoch 103/200, Train Loss: 1.4883\n",
      "[INFO]......... [TRAINING MSG>>>]..... Epoch 104/200, Train Loss: 1.4988\n",
      "[INFO]......... [TRAINING MSG>>>]..... Epoch 105/200, Train Loss: 1.4944\n",
      "[INFO]......... [TRAINING MSG>>>]..... Epoch 106/200, Train Loss: 1.4964\n",
      "[INFO]......... [TRAINING MSG>>>]..... Epoch 107/200, Train Loss: 1.4993\n",
      "[INFO]......... [TRAINING MSG>>>]..... Epoch 108/200, Train Loss: 1.4924\n",
      "[INFO]......... [TRAINING MSG>>>]..... Epoch 109/200, Train Loss: 1.4954\n",
      "[INFO]......... [TRAINING MSG>>>]..... Epoch 110/200, Train Loss: 1.4873\n",
      "[INFO]......... [TRAINING MSG>>>]..... Epoch 111/200, Train Loss: 1.4948\n",
      "[INFO]......... [TRAINING MSG>>>]..... Epoch 112/200, Train Loss: 1.4843\n",
      "[INFO]......... [TRAINING MSG>>>]..... Epoch 113/200, Train Loss: 1.4893\n",
      "[INFO]......... [TRAINING MSG>>>]..... Epoch 114/200, Train Loss: 1.4944\n",
      "[INFO]......... [TRAINING MSG>>>]..... Epoch 115/200, Train Loss: 1.4914\n",
      "[INFO]......... [TRAINING MSG>>>]..... Epoch 116/200, Train Loss: 1.4873\n",
      "[INFO]......... [TRAINING MSG>>>]..... Epoch 117/200, Train Loss: 1.4904\n",
      "[INFO]......... [TRAINING MSG>>>]..... Epoch 118/200, Train Loss: 1.4904\n",
      "[INFO]......... [TRAINING MSG>>>]..... Epoch 119/200, Train Loss: 1.5034\n",
      "[INFO]......... [TRAINING MSG>>>]..... Epoch 120/200, Train Loss: 1.4950\n",
      "[INFO]......... [TRAINING MSG>>>]..... Epoch 121/200, Train Loss: 1.4965\n",
      "[INFO]......... [TRAINING MSG>>>]..... Epoch 122/200, Train Loss: 1.4904\n",
      "[INFO]......... [TRAINING MSG>>>]..... Epoch 123/200, Train Loss: 1.4904\n",
      "[INFO]......... [TRAINING MSG>>>]..... Epoch 124/200, Train Loss: 1.4833\n",
      "[INFO]......... [TRAINING MSG>>>]..... Epoch 125/200, Train Loss: 1.4974\n",
      "[INFO]......... [TRAINING MSG>>>]..... Epoch 126/200, Train Loss: 1.5004\n",
      "[INFO]......... [TRAINING MSG>>>]..... Epoch 127/200, Train Loss: 1.4964\n",
      "[INFO]......... [TRAINING MSG>>>]..... Epoch 128/200, Train Loss: 1.4884\n",
      "[INFO]......... [TRAINING MSG>>>]..... Epoch 129/200, Train Loss: 1.4773\n",
      "[INFO]......... [TRAINING MSG>>>]..... Epoch 130/200, Train Loss: 1.5004\n",
      "[INFO]......... [TRAINING MSG>>>]..... Epoch 131/200, Train Loss: 1.4974\n",
      "[INFO]......... [TRAINING MSG>>>]..... Epoch 132/200, Train Loss: 1.5014\n",
      "[INFO]......... [TRAINING MSG>>>]..... Epoch 133/200, Train Loss: 1.4994\n",
      "[INFO]......... [TRAINING MSG>>>]..... Epoch 134/200, Train Loss: 1.4903\n",
      "[INFO]......... [TRAINING MSG>>>]..... Epoch 135/200, Train Loss: 1.4900\n",
      "[INFO]......... [TRAINING MSG>>>]..... Epoch 136/200, Train Loss: 1.4873\n",
      "[INFO]......... [TRAINING MSG>>>]..... Epoch 137/200, Train Loss: 1.4934\n",
      "[INFO]......... [TRAINING MSG>>>]..... Epoch 138/200, Train Loss: 1.4903\n",
      "[INFO]......... [TRAINING MSG>>>]..... Epoch 139/200, Train Loss: 1.4934\n",
      "[INFO]......... [TRAINING MSG>>>]..... Epoch 140/200, Train Loss: 1.4863\n",
      "[INFO]......... [TRAINING MSG>>>]..... Epoch 141/200, Train Loss: 1.4853\n",
      "[INFO]......... [TRAINING MSG>>>]..... Epoch 142/200, Train Loss: 1.4932\n",
      "[INFO]......... [TRAINING MSG>>>]..... Epoch 143/200, Train Loss: 1.4874\n",
      "[INFO]......... [TRAINING MSG>>>]..... Epoch 144/200, Train Loss: 1.4901\n",
      "[INFO]......... [TRAINING MSG>>>]..... Epoch 145/200, Train Loss: 1.4994\n",
      "[INFO]......... [TRAINING MSG>>>]..... Epoch 146/200, Train Loss: 1.5085\n",
      "[INFO]......... [TRAINING MSG>>>]..... Epoch 147/200, Train Loss: 1.4906\n",
      "[INFO]......... [TRAINING MSG>>>]..... Epoch 148/200, Train Loss: 1.4854\n",
      "[INFO]......... [TRAINING MSG>>>]..... Epoch 149/200, Train Loss: 1.4883\n",
      "[INFO]......... [TRAINING MSG>>>]..... Epoch 150/200, Train Loss: 1.4924\n",
      "[INFO]......... [TRAINING MSG>>>]..... Epoch 151/200, Train Loss: 1.4954\n",
      "[INFO]......... [TRAINING MSG>>>]..... Epoch 152/200, Train Loss: 1.5014\n",
      "[INFO]......... [TRAINING MSG>>>]..... Epoch 153/200, Train Loss: 1.4934\n",
      "[INFO]......... [TRAINING MSG>>>]..... Epoch 154/200, Train Loss: 1.4994\n",
      "[INFO]......... [TRAINING MSG>>>]..... Epoch 155/200, Train Loss: 1.4957\n",
      "[INFO]......... [TRAINING MSG>>>]..... Epoch 156/200, Train Loss: 1.4954\n",
      "[INFO]......... [TRAINING MSG>>>]..... Epoch 157/200, Train Loss: 1.4954\n",
      "[INFO]......... [TRAINING MSG>>>]..... Epoch 158/200, Train Loss: 1.4863\n",
      "[INFO]......... [TRAINING MSG>>>]..... Epoch 159/200, Train Loss: 1.4906\n",
      "[INFO]......... [TRAINING MSG>>>]..... Epoch 160/200, Train Loss: 1.4954\n",
      "[INFO]......... [TRAINING MSG>>>]..... Epoch 161/200, Train Loss: 1.4843\n",
      "[INFO]......... [TRAINING MSG>>>]..... Epoch 162/200, Train Loss: 1.4954\n",
      "[INFO]......... [TRAINING MSG>>>]..... Epoch 163/200, Train Loss: 1.4964\n",
      "[INFO]......... [TRAINING MSG>>>]..... Epoch 164/200, Train Loss: 1.4933\n",
      "[INFO]......... [TRAINING MSG>>>]..... Epoch 165/200, Train Loss: 1.4833\n",
      "[INFO]......... [TRAINING MSG>>>]..... Epoch 166/200, Train Loss: 1.5014\n",
      "[INFO]......... [TRAINING MSG>>>]..... Epoch 167/200, Train Loss: 1.4893\n",
      "[INFO]......... [TRAINING MSG>>>]..... Epoch 168/200, Train Loss: 1.4803\n",
      "[INFO]......... [TRAINING MSG>>>]..... Epoch 169/200, Train Loss: 1.4926\n",
      "[INFO]......... [TRAINING MSG>>>]..... Epoch 170/200, Train Loss: 1.4944\n",
      "[INFO]......... [TRAINING MSG>>>]..... Epoch 171/200, Train Loss: 1.4994\n",
      "[INFO]......... [TRAINING MSG>>>]..... Epoch 172/200, Train Loss: 1.4893\n",
      "[INFO]......... [TRAINING MSG>>>]..... Epoch 173/200, Train Loss: 1.4938\n",
      "[INFO]......... [TRAINING MSG>>>]..... Epoch 174/200, Train Loss: 1.4904\n",
      "[INFO]......... [TRAINING MSG>>>]..... Epoch 175/200, Train Loss: 1.4904\n",
      "[INFO]......... [TRAINING MSG>>>]..... Epoch 176/200, Train Loss: 1.4924\n",
      "[INFO]......... [TRAINING MSG>>>]..... Epoch 177/200, Train Loss: 1.4853\n",
      "[INFO]......... [TRAINING MSG>>>]..... Epoch 178/200, Train Loss: 1.4984\n",
      "[INFO]......... [TRAINING MSG>>>]..... Epoch 179/200, Train Loss: 1.4924\n",
      "[INFO]......... [TRAINING MSG>>>]..... Epoch 180/200, Train Loss: 1.4914\n",
      "[INFO]......... [TRAINING MSG>>>]..... Epoch 181/200, Train Loss: 1.4951\n",
      "[INFO]......... [TRAINING MSG>>>]..... Epoch 182/200, Train Loss: 1.5024\n",
      "[INFO]......... [TRAINING MSG>>>]..... Epoch 183/200, Train Loss: 1.4873\n",
      "[INFO]......... [TRAINING MSG>>>]..... Epoch 184/200, Train Loss: 1.4893\n",
      "[INFO]......... [TRAINING MSG>>>]..... Epoch 185/200, Train Loss: 1.5014\n",
      "[INFO]......... [TRAINING MSG>>>]..... Epoch 186/200, Train Loss: 1.4974\n",
      "[INFO]......... [TRAINING MSG>>>]..... Epoch 187/200, Train Loss: 1.4855\n",
      "[INFO]......... [TRAINING MSG>>>]..... Epoch 188/200, Train Loss: 1.4974\n",
      "[INFO]......... [TRAINING MSG>>>]..... Epoch 189/200, Train Loss: 1.4964\n",
      "[INFO]......... [TRAINING MSG>>>]..... Epoch 190/200, Train Loss: 1.4954\n",
      "[INFO]......... [TRAINING MSG>>>]..... Epoch 191/200, Train Loss: 1.4926\n",
      "[INFO]......... [TRAINING MSG>>>]..... Epoch 192/200, Train Loss: 1.4843\n",
      "[INFO]......... [TRAINING MSG>>>]..... Epoch 193/200, Train Loss: 1.4994\n",
      "[INFO]......... [TRAINING MSG>>>]..... Epoch 194/200, Train Loss: 1.4964\n",
      "[INFO]......... [TRAINING MSG>>>]..... Epoch 195/200, Train Loss: 1.4873\n",
      "[INFO]......... [TRAINING MSG>>>]..... Epoch 196/200, Train Loss: 1.4974\n",
      "[INFO]......... [TRAINING MSG>>>]..... Epoch 197/200, Train Loss: 1.4994\n",
      "[INFO]......... [TRAINING MSG>>>]..... Epoch 198/200, Train Loss: 1.4934\n",
      "[INFO]......... [TRAINING MSG>>>]..... Epoch 199/200, Train Loss: 1.4883\n",
      "[INFO]......... [TRAINING MSG>>>]..... Epoch 200/200, Train Loss: 1.4904\n",
      "[INFO]......... Checkpoint saved at epoch 199.\n",
      "[INFO]......... Successfully saved checkpoint: transformer_0_chk\n",
      "[INFO]......... Successfully saved transformer model: model_.pth\n"
     ]
    }
   ],
   "source": [
    "trainLosses, model=trainer.trainModel( \"transformer\",batchSize=1024,\n",
    "                                      currentCheckPointPath=\"transformer_0_chk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "l-0metCYZWmu",
    "outputId": "1f891e0c-429b-4a5a-e9b3-319fab7783ae"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-6486d8d46c39>:146: UserWarning: set_ticklabels() should only be used with a fixed number of ticks, i.e. after set_ticks() or using a FixedLocator.\n",
      "  ax.set_xticklabels( ax.get_xticklabels( ), fontdict=self.FDICT_PLOTS )\n",
      "<ipython-input-11-6486d8d46c39>:147: UserWarning: set_ticklabels() should only be used with a fixed number of ticks, i.e. after set_ticks() or using a FixedLocator.\n",
      "  ax.set_yticklabels( ax.get_yticklabels( ), fontdict=self.FDICT_PLOTS )\n",
      "[WARNING]......... findfont: Font family 'Arial' not found.\n",
      "[WARNING]......... findfont: Font family 'Arial' not found.\n",
      "[WARNING]......... findfont: Font family 'Arial' not found.\n",
      "[WARNING]......... findfont: Font family 'Arial' not found.\n",
      "[WARNING]......... findfont: Font family 'Arial' not found.\n",
      "[WARNING]......... findfont: Font family 'Arial' not found.\n",
      "[WARNING]......... findfont: Font family 'Arial' not found.\n",
      "[WARNING]......... findfont: Font family 'Arial' not found.\n",
      "[WARNING]......... findfont: Font family 'Arial' not found.\n",
      "[WARNING]......... findfont: Font family 'Arial' not found.\n",
      "[WARNING]......... findfont: Font family 'Arial' not found.\n",
      "[WARNING]......... findfont: Font family 'Arial' not found.\n",
      "[WARNING]......... findfont: Font family 'Arial' not found.\n",
      "[WARNING]......... findfont: Font family 'Arial' not found.\n",
      "[WARNING]......... findfont: Font family 'Arial' not found.\n",
      "[WARNING]......... findfont: Font family 'Arial' not found.\n",
      "[WARNING]......... findfont: Font family 'Arial' not found.\n",
      "[WARNING]......... findfont: Font family 'Arial' not found.\n",
      "[WARNING]......... findfont: Font family 'Arial' not found.\n",
      "[WARNING]......... findfont: Font family 'Arial' not found.\n",
      "[WARNING]......... findfont: Font family 'Arial' not found.\n",
      "[WARNING]......... findfont: Font family 'Arial' not found.\n",
      "[WARNING]......... findfont: Font family 'Arial' not found.\n",
      "[WARNING]......... findfont: Font family 'Arial' not found.\n",
      "[WARNING]......... findfont: Font family 'Arial' not found.\n",
      "[WARNING]......... findfont: Font family 'Arial' not found.\n",
      "[WARNING]......... findfont: Font family 'Arial' not found.\n",
      "[WARNING]......... findfont: Font family 'Arial' not found.\n",
      "[WARNING]......... findfont: Font family 'Arial' not found.\n",
      "[WARNING]......... findfont: Font family 'Arial' not found.\n",
      "[WARNING]......... findfont: Font family 'Arial' not found.\n",
      "[WARNING]......... findfont: Font family 'Arial' not found.\n",
      "[WARNING]......... findfont: Font family 'Arial' not found.\n",
      "[WARNING]......... findfont: Font family 'Arial' not found.\n",
      "[WARNING]......... findfont: Font family 'Arial' not found.\n",
      "[WARNING]......... findfont: Font family 'Arial' not found.\n",
      "[WARNING]......... findfont: Font family 'Arial' not found.\n",
      "[WARNING]......... findfont: Font family 'Arial' not found.\n",
      "[WARNING]......... findfont: Font family 'Arial' not found.\n",
      "[WARNING]......... findfont: Font family 'Arial' not found.\n",
      "[WARNING]......... findfont: Font family 'Arial' not found.\n",
      "[WARNING]......... findfont: Font family 'Arial' not found.\n",
      "[WARNING]......... findfont: Font family 'Arial' not found.\n",
      "[WARNING]......... findfont: Font family 'Arial' not found.\n",
      "[WARNING]......... findfont: Font family 'Arial' not found.\n",
      "[WARNING]......... findfont: Font family 'Arial' not found.\n",
      "[WARNING]......... findfont: Font family 'Arial' not found.\n",
      "[WARNING]......... findfont: Font family 'Arial' not found.\n",
      "[WARNING]......... findfont: Font family 'Arial' not found.\n",
      "[WARNING]......... findfont: Font family 'Arial' not found.\n",
      "[WARNING]......... findfont: Font family 'Arial' not found.\n",
      "[WARNING]......... findfont: Font family 'Arial' not found.\n",
      "[WARNING]......... findfont: Font family 'Arial' not found.\n",
      "[WARNING]......... findfont: Font family 'Arial' not found.\n",
      "[WARNING]......... findfont: Font family 'Arial' not found.\n",
      "[WARNING]......... findfont: Font family 'Arial' not found.\n",
      "[WARNING]......... findfont: Font family 'Arial' not found.\n",
      "[WARNING]......... findfont: Font family 'Arial' not found.\n",
      "[WARNING]......... findfont: Font family 'Arial' not found.\n",
      "[WARNING]......... findfont: Font family 'Arial' not found.\n",
      "[WARNING]......... findfont: Font family 'Arial' not found.\n",
      "[WARNING]......... findfont: Font family 'Arial' not found.\n",
      "[WARNING]......... findfont: Font family 'Arial' not found.\n",
      "[WARNING]......... findfont: Font family 'Arial' not found.\n",
      "[WARNING]......... findfont: Font family 'Arial' not found.\n",
      "[WARNING]......... findfont: Font family 'Arial' not found.\n",
      "[WARNING]......... findfont: Font family 'Arial' not found.\n",
      "[WARNING]......... findfont: Font family 'Arial' not found.\n",
      "[WARNING]......... findfont: Font family 'Arial' not found.\n",
      "[WARNING]......... findfont: Font family 'Arial' not found.\n",
      "[WARNING]......... findfont: Font family 'Arial' not found.\n",
      "[WARNING]......... findfont: Font family 'Arial' not found.\n",
      "[WARNING]......... findfont: Font family 'Arial' not found.\n",
      "[WARNING]......... findfont: Font family 'Arial' not found.\n",
      "[WARNING]......... findfont: Font family 'Arial' not found.\n",
      "[WARNING]......... findfont: Font family 'Arial' not found.\n",
      "[WARNING]......... findfont: Font family 'Arial' not found.\n",
      "[WARNING]......... findfont: Font family 'Arial' not found.\n",
      "[WARNING]......... findfont: Font family 'Arial' not found.\n",
      "[WARNING]......... findfont: Font family 'Arial' not found.\n",
      "[WARNING]......... findfont: Font family 'Arial' not found.\n",
      "[WARNING]......... findfont: Font family 'Arial' not found.\n",
      "[WARNING]......... findfont: Font family 'Arial' not found.\n",
      "[WARNING]......... findfont: Font family 'Arial' not found.\n",
      "[WARNING]......... findfont: Font family 'Arial' not found.\n",
      "[WARNING]......... findfont: Font family 'Arial' not found.\n",
      "[WARNING]......... findfont: Font family 'Arial' not found.\n",
      "[WARNING]......... findfont: Font family 'Arial' not found.\n",
      "[WARNING]......... findfont: Font family 'Arial' not found.\n",
      "[WARNING]......... findfont: Font family 'Arial' not found.\n",
      "[WARNING]......... findfont: Font family 'Arial' not found.\n",
      "[WARNING]......... findfont: Font family 'Arial' not found.\n",
      "[WARNING]......... findfont: Font family 'Arial' not found.\n",
      "[WARNING]......... findfont: Font family 'Arial' not found.\n",
      "[WARNING]......... findfont: Font family 'Arial' not found.\n",
      "[WARNING]......... findfont: Font family 'Arial' not found.\n",
      "[WARNING]......... findfont: Font family 'Arial' not found.\n",
      "[WARNING]......... findfont: Font family 'Arial' not found.\n",
      "[WARNING]......... findfont: Font family 'Arial' not found.\n",
      "[WARNING]......... findfont: Font family 'Arial' not found.\n",
      "[WARNING]......... findfont: Font family 'Arial' not found.\n",
      "[WARNING]......... findfont: Font family 'Arial' not found.\n",
      "[WARNING]......... findfont: Font family 'Arial' not found.\n",
      "[WARNING]......... findfont: Font family 'Arial' not found.\n",
      "[WARNING]......... findfont: Font family 'Arial' not found.\n",
      "[WARNING]......... findfont: Font family 'Arial' not found.\n",
      "[WARNING]......... findfont: Font family 'Arial' not found.\n",
      "[WARNING]......... findfont: Font family 'Arial' not found.\n",
      "[WARNING]......... findfont: Font family 'Arial' not found.\n",
      "[WARNING]......... findfont: Font family 'Arial' not found.\n",
      "[WARNING]......... findfont: Font family 'Arial' not found.\n",
      "[WARNING]......... findfont: Font family 'Arial' not found.\n",
      "[WARNING]......... findfont: Font family 'Arial' not found.\n",
      "[WARNING]......... findfont: Font family 'Arial' not found.\n",
      "[WARNING]......... findfont: Font family 'Arial' not found.\n",
      "[WARNING]......... findfont: Font family 'Arial' not found.\n",
      "[WARNING]......... findfont: Font family 'Arial' not found.\n",
      "[WARNING]......... findfont: Font family 'Arial' not found.\n",
      "[WARNING]......... findfont: Font family 'Arial' not found.\n",
      "[WARNING]......... findfont: Font family 'Arial' not found.\n",
      "[WARNING]......... findfont: Font family 'Arial' not found.\n",
      "[WARNING]......... findfont: Font family 'Arial' not found.\n",
      "[WARNING]......... findfont: Font family 'Arial' not found.\n",
      "[WARNING]......... findfont: Font family 'Arial' not found.\n",
      "[WARNING]......... findfont: Font family 'Arial' not found.\n",
      "[WARNING]......... findfont: Font family 'Arial' not found.\n",
      "[WARNING]......... findfont: Font family 'Arial' not found.\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 683x333 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer.plotLosses( trainLosses,None )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bTNBbonFVOef"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
